# ReadMe - Local AI Reading Assistant

A self-hosted desktop application that converts digital books and documents into natural-sounding speech with AI-powered summaries. Built with Electron, React, and FastAPI.

## ğŸ¯ Features

- **File Format Support**: `.txt`, `.md`, `.pdf`, `.epub`, `.docx` files
- **Smart Content Filtering**: skips frontmatter, page numbers, footnotes, and repeated headers/footers
- **Sentence-level Parsing**: content stored as sentences for precise highlighting
- **Text-Audio Synchronization**: real-time sentence highlighting during playback (Phase 7)
- **Adaptive Speed**: automatically increases reading speed over time (1.5Ã— â†’ 2.5Ã—)
- **Basic Playback State API**: track position and speed locally
- **Privacy-first**: local-first architecture with optional Heroku/OpenAI fallback
- **Offline Mode**: fully functional with Coqui TTS on the SSH boxâ€”no API calls required
- **Downloadable Audio**: each synthesis job exposes a direct WAV/MP3 download link

## ğŸ“š Table of Contents

1. [Architecture](#-architecture)
2. [Prerequisites](#-prerequisites)
3. [Quick Start](#-quick-start)
4. [Local vs Cloud TTS](#-local-tts-coqui)
5. [Project Structure](#-project-structure)
6. [Development](#-development)
7. [Roadmap](#-roadmap)
8. [Security](#-security)
9. [Contributing](#-contributing)
10. [License](#-license)
11. [Acknowledgments](#-acknowledgments)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Electron UI   â”‚â”€â”€â”€â”€â–ºâ”‚ Local FastAPIâ”‚â”€â”€â”€â”€â–ºâ”‚   Cloud     â”‚
â”‚ (React)       â”‚     â”‚ (Python)     â”‚     â”‚ (Optional)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²                     â”‚                     â”‚
        â”‚                     â–¼                     â–¼
        â”‚            SQLite / Parsers      OpenAI TTS / GPT
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Playback & UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

- Frontend: Electron + React (minimal UI; Phase 4 completed)
- Backend: FastAPI (Python) on localhost:5000 (v0.3.0)
- Database: SQLite (single-book state)
- Parsing: `.txt`/`.md` supported now; PDF/EPUB/DOCX planned
- Cloud (Optional): Separate service (see readme-cloud repo)

## ğŸ“‹ Prerequisites

- **Python 3.11+** with pip
- **Node.js 18+** with npm
- **OpenAI API Key** (optional; required for cloud TTS/summarization)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/crichalchemist/ReadMeLocal
cd ReadMeLocal
```

### 2. Set Up Backend

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Set Up Frontend

```bash
cd ../frontend

# Install dependencies
npm install
```

### 4. Configure Environment

```bash
# Copy the template
cp config/secrets.env.template config/secrets.env

# Edit config/secrets.env and add your OpenAI API key
# OPENAI_API_KEY=sk-your-key-here
```

### 5. Run the Application

Start the app (Electron will auto-start the Python backend):
```bash
cd frontend
npm run electron-dev
```

The app will automatically:
1. Start the Python backend server on `localhost:5000`
2. Launch the React development server
3. Open the Electron desktop application

## ğŸ”Š Local TTS (Coqui)

Run the text-to-speech pipeline completely on the SSH server with [Coqui TTS](https://github.com/coqui-ai/TTS) to avoid external API costs.

1. Install backend dependencies (includes the `TTS` package which downloads PyTorch automatically):
   ```bash
   cd backend
   pip install -r requirements.txt
   ```
2. Enable/adjust the local voice in `config/settings.yaml`:
   ```yaml
   tts_default: "local"
   local_tts:
     enabled: true
     provider: "coqui"
     model_name: "tts_models/en/vctk/vits"
     default_voice: "coqui_en"
   voices:
     - name: "coqui_en"
       type: "local"
       enabled: true
       speaker: "p273"
       language: "en"
   ```
3. Start the backend or Electron app. On the first request the model will be downloaded (~1 GB) and subsequent conversions will be cached under `cache/audio/`.
4. Trigger TTS from the UI; when a local voice is selected, the backend calls Coqui and returns both a streaming URL and `/api/audio/{job_id}/download`.
5. Click **Download audio** to save the generated `.wav`/`.mp3` file, or call the API directly:
   ```bash
   curl -L -o output.wav "http://localhost:5000/api/audio/<job_id>/download"
   ```
6. Cloud/OpenAI voices remain available; change the voice selector to a cloud voice to send the same request through the Heroku API.

### Switching modes

- **Local-first**: set `tts_default: "local"` and keep a local voice selected. No OpenAI/Heroku keys requiredâ€”ideal for offline sessions or avoiding per-character billing.
- **Cloud fallback**: pick any `type: "cloud"` voice or send `mode: "cloud"` in `/api/tts` to route through Heroku/OpenAI. Useful when you need a different voice or when the local GPU/CPU is busy.
- **Hybrid**: keep multiple voices configured and switch on-demand in the React UI; the backend will automatically pick the correct mode based on the selected voice.

## ğŸ“¦ Project Structure

```
ReadMeLocal/
â”œâ”€â”€ backend/                  # Python FastAPI server (local)
â”‚   â”œâ”€â”€ main.py              # Entry point (v0.3.0)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ frontend/                 # Electron + React app
â”‚   â”œâ”€â”€ electron/
â”‚   â”‚   â”œâ”€â”€ main.js          # Window management & IPC
â”‚   â”‚   â””â”€â”€ preload.js       # Security bridge
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ config/                   # Configuration files
â”‚   â”œâ”€â”€ settings.yaml        # App settings (incl. content_filtering)
â”‚   â””â”€â”€ secrets.env.template # API keys template (copy to secrets.env)
â”œâ”€â”€ db/                      # SQLite database (runtime)
â”œâ”€â”€ README.md
â”œâ”€â”€ revisedplan.md
â”œâ”€â”€ CHECKPOINT_1.md
â””â”€â”€ .junie/
    â””â”€â”€ guidelines.md
```

Note: Cloud backend (Heroku) lives in a separate repository (readme-cloud).

## ğŸ”§ Development

### Backend Development

```bash
cd backend
source venv/bin/activate

# Run with auto-reload
uvicorn main:app --reload --host 127.0.0.1 --port 5000

# Run tests
pytest

# Format code
black .
```

### Frontend Development

```bash
cd frontend

# Run React dev server only
npm start

# Run Electron with React
npm run electron-dev

# Build for production
npm run build
npm run electron-build
```

### API Documentation

Once the backend is running, visit:
- **Interactive API Docs**: http://localhost:5000/docs
- **Alternative Docs**: http://localhost:5000/redoc

## ğŸ—ºï¸ Roadmap

### Phase 1 â€” Project Setup âœ“
- Project scaffolding, Electron + React shell, FastAPI skeleton

### Phase 2 â€” Core Backend (Singleâ€‘Book) âœ“
- Current book import endpoints (.txt/.md)
- Playback state (position, speed)

### Phase 3 â€” Smart Content Parsing âœ“
- ContentFilter: skip frontmatter, page numbers, footnotes, repeated headers/footers
- Store content as sentences
- Backend version bumped to v0.3.0

### Phase 4 â€” Minimalistic UI âœ“
- Empty state with drop zone and Select File button
- Reading view with sentence highlighting and autoâ€‘scroll
- Basic playback controls (play/pause, speed indicator)

### Phase 5 â€” Cloud TTS Integration âœ“
- Heroku service hookup (OpenAI TTS)
- Local audio caching and streaming endpoint

### Phase 6 â€” Adaptive Speed âœ“
- Incremental speed adjustments over session (1.5Ã— start; +0.1Ã— every 15 min; capped at 2.5Ã—)

### Phase 7 â€” Textâ€“Audio Sync âœ“
- Estimate sentence durations and realâ€‘time highlighting

### Phase 8 â€” Singleâ€‘Book Lock
- Prevent opening a second book until current is closed

## ğŸ” Security

- Backend only binds to `localhost` (not exposed to network)
- All cloud communication uses HTTPS
- API keys stored in git-ignored `secrets.env`
- No telemetry or external tracking
- Electron security best practices (contextIsolation, no nodeIntegration)

## ğŸ¤ Contributing

This is a personal project, but suggestions and feedback are welcome! Please open an issue to discuss any changes.

## ğŸ“„ License

[Your chosen license]

## ğŸ™ Acknowledgments

- OpenAI for GPT and TTS APIs
- FastAPI and Electron communities
- Open source document parsing libraries

---

**Status**: ğŸš§ In Development (Phase 8 â€” Singleâ€“Book Lock next) Â· Backend v0.3.0

For detailed technical specifications, see [.junie/guidelines.md](.junie/guidelines.md)

---

## Sprint Reader Rebuild (Visual-Only)

If you are rebuilding this project into a **visual-only sprint reader** (no TTS), refer to the detailed plan here:

- [docs/sprint-reader-plan.md](docs/sprint-reader-plan.md)

This plan targets a **single-word, minimal black screen** reading mode with local-only parsing for PDF/EPUB first.
